{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "att_scores = torch.empty(inputs.shape[0])\n",
    "\n",
    "for idx,input in enumerate(inputs):\n",
    "    att_scores[idx] = torch.dot(query, input)\n",
    "\n",
    "att_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_wei = att_scores / att_scores.sum()\n",
    "att_wei\n",
    "# att_wei.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax_na(x):\n",
    "    return torch.exp(x) / torch.sum(torch.exp(x), dim=0)\n",
    "\n",
    "\n",
    "softmax_na(att_scores)\n",
    "softmax_na(att_scores).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(att_scores,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4419, 0.6515, 0.5683])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_wei = torch.softmax(att_scores,dim=0)\n",
    "\n",
    "context_vec = torch.zeros(inputs[0].shape)\n",
    "\n",
    "for idx,input in enumerate(inputs):\n",
    "    context_vec = context_vec + att_wei[idx] * input\n",
    "\n",
    "context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310])\n",
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n",
      "tensor([0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605])\n",
      "tensor([0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565])\n",
      "tensor([0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935])\n",
      "tensor([0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450])\n",
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n",
      "tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "inputs\n",
    "\n",
    "scores = torch.empty((inputs.shape[0],inputs.shape[0]))\n",
    "\n",
    "for idx,input in enumerate(inputs):\n",
    "    scores[idx] = input @ inputs.T\n",
    "    print(input @ inputs.T)\n",
    "\n",
    "scores = inputs @ inputs.T\n",
    "    \n",
    "print(scores)\n",
    "\n",
    "\n",
    "print(torch.softmax(torch.tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865]),dim=0))\n",
    "\n",
    "print(torch.softmax(scores,dim=1))\n",
    "\n",
    "print(torch.softmax(scores,dim=1)[1].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = torch.softmax(scores,dim=1)\n",
    "\n",
    "weight.shape\n",
    "\n",
    "context_vec = weight @ inputs\n",
    "context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.2961, 0.5166],\n",
       "         [0.2517, 0.6886],\n",
       "         [0.0740, 0.8665]]),\n",
       " Parameter containing:\n",
       " tensor([[0.1366, 0.1025],\n",
       "         [0.1841, 0.7264],\n",
       "         [0.3153, 0.6871]]),\n",
       " Parameter containing:\n",
       " tensor([[0.0756, 0.1966],\n",
       "         [0.3164, 0.4017],\n",
       "         [0.1186, 0.8274]]))"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2\n",
    "\n",
    "w_q = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "w_k = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "w_v = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "\n",
    "w_q,w_k,w_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4306, 1.4551]), tensor([0.4433, 1.1419]), tensor([0.3951, 1.0037]))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_2 = inputs[1]\n",
    "\n",
    "q_2 = x_2 @ w_q\n",
    "k_2 = x_2 @ w_k\n",
    "v_2 = x_2 @ w_v\n",
    "\n",
    "q_2,k_2,v_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2309, 1.0966],\n",
       "         [0.4306, 1.4551],\n",
       "         [0.4300, 1.4343],\n",
       "         [0.2355, 0.7990],\n",
       "         [0.2983, 0.6565],\n",
       "         [0.2568, 1.0533]]),\n",
       " tensor([[0.1855, 0.8812],\n",
       "         [0.3951, 1.0037],\n",
       "         [0.3879, 0.9831],\n",
       "         [0.2393, 0.5493],\n",
       "         [0.1492, 0.3346],\n",
       "         [0.3221, 0.7863]]))"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys = inputs @ w_q\n",
    "values = inputs @ w_v\n",
    "\n",
    "keys,values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3026)\n",
      "tensor([1.6951, 2.3026, 2.2722, 1.2640, 1.0838, 1.6432])\n"
     ]
    }
   ],
   "source": [
    "k_2 = keys[1]\n",
    "ant_score_22 = q_2.dot(k_2)\n",
    "print(ant_score_22)\n",
    "\n",
    "ant_score_2 = q_2 @ keys.T\n",
    "print(ant_score_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1565, 0.2404, 0.2353, 0.1154, 0.1016, 0.1508])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = keys.shape[1]\n",
    "\n",
    "ant_weight_2 = torch.softmax(ant_score_2/d_k**0.5,dim=0)\n",
    "ant_weight_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3067, 0.8265])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec_2 = ant_weight_2 @ values\n",
    "context_vec_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2961, 0.5166],\n",
      "        [0.2517, 0.6886],\n",
      "        [0.0740, 0.8665]])\n",
      "tensor([[0.2309, 1.0966],\n",
      "        [0.4306, 1.4551],\n",
      "        [0.4300, 1.4343],\n",
      "        [0.2355, 0.7990],\n",
      "        [0.2983, 0.6565],\n",
      "        [0.2568, 1.0533]])\n",
      "tensor([[1.2559, 1.6951, 1.6722, 0.9305, 0.7889, 1.2143],\n",
      "        [1.6951, 2.3026, 2.2722, 1.2640, 1.0838, 1.6432],\n",
      "        [1.6722, 2.2722, 2.2421, 1.2472, 1.0700, 1.6211],\n",
      "        [0.9305, 1.2640, 1.2472, 0.6938, 0.5948, 0.9020],\n",
      "        [0.7889, 1.0838, 1.0700, 0.5948, 0.5200, 0.7681],\n",
      "        [1.2143, 1.6432, 1.6211, 0.9020, 0.7681, 1.1753]])\n",
      "tensor([[0.1615, 0.2204, 0.2168, 0.1283, 0.1161, 0.1569],\n",
      "        [0.1565, 0.2404, 0.2353, 0.1154, 0.1016, 0.1508],\n",
      "        [0.1567, 0.2395, 0.2344, 0.1160, 0.1023, 0.1511],\n",
      "        [0.1631, 0.2065, 0.2040, 0.1380, 0.1286, 0.1598],\n",
      "        [0.1630, 0.2008, 0.1988, 0.1421, 0.1348, 0.1606],\n",
      "        [0.1615, 0.2187, 0.2153, 0.1295, 0.1178, 0.1571]])\n",
      "tensor([[0.2997, 0.8094],\n",
      "        [0.3067, 0.8265],\n",
      "        [0.3063, 0.8256],\n",
      "        [0.2947, 0.7960],\n",
      "        [0.2925, 0.7900],\n",
      "        [0.2991, 0.8077]])\n"
     ]
    }
   ],
   "source": [
    "print(w_q)\n",
    "\n",
    "query = inputs @ w_q\n",
    "print(query)\n",
    "\n",
    "\n",
    "ant_score = query @ keys.T\n",
    "print(ant_score)\n",
    "\n",
    "ant_wei = torch.softmax(ant_score/d_k**0.5, dim=1)\n",
    "print(ant_wei)\n",
    "\n",
    "\n",
    "ant_ctx_vec = ant_wei @ values\n",
    "\n",
    "print(ant_ctx_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttV1:\n",
    "    def __init__(self,d_in,d_out) -> None:\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        \n",
    "        self.q = torch.nn.Parameter(torch.randn(d_in,d_out),requires_grad=False)\n",
    "        self.k = torch.nn.Parameter(torch.randn(d_in,d_out),requires_grad=False)\n",
    "        self.v = torch.nn.Parameter(torch.randn(d_in,d_out),requires_grad=False)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_q = x @ self.q\n",
    "        x_k = x @ self.k\n",
    "        x_v = x @ self.v\n",
    "\n",
    "        print(self.q)\n",
    "        \n",
    "        print(x_q)\n",
    "        x_ant_score = x_q @ x_k.T\n",
    "        # print(x_ant_score)\n",
    "        x_ant_wei = torch.softmax(x_ant_score/self.d_out**0.5,dim=1)\n",
    "        # print(x_ant_wei)\n",
    "        x_ctx_vec = x_ant_wei @ x_v\n",
    "\n",
    "        return x_ctx_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1115,  0.1204],\n",
      "        [-0.3696, -0.2404],\n",
      "        [-1.1969,  0.2093]])\n",
      "tensor([[-1.1686,  0.2019],\n",
      "        [-1.1729, -0.0048],\n",
      "        [-1.1438, -0.0018],\n",
      "        [-0.6339, -0.0439],\n",
      "        [-0.2979,  0.0535],\n",
      "        [-0.9596, -0.0712]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2845, 0.4071],\n",
       "        [0.2854, 0.4081],\n",
       "        [0.2854, 0.4075],\n",
       "        [0.2864, 0.3974],\n",
       "        [0.2863, 0.3910],\n",
       "        [0.2860, 0.4039]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_in = 3\n",
    "d_out = 2\n",
    "\n",
    "sa = SimpleAttV1(d_in,d_out)\n",
    "\n",
    "x_ctx = sa.forward(inputs)\n",
    "x_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttV2:\n",
    "    def __init__(self,d_in,d_out,bias=False) -> None:\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        \n",
    "        self.q = torch.nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.k = torch.nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.v = torch.nn.Linear(d_in,d_out,bias=bias)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_q = self.q(x)\n",
    "        x_k = self.k(x)\n",
    "        x_v = self.v(x)\n",
    "\n",
    "        # print(self.q)\n",
    "        \n",
    "        # print(x_q)\n",
    "        x_ant_score = x_q @ x_k.T\n",
    "        # print(x_ant_score)\n",
    "        x_ant_wei = torch.softmax(x_ant_score/self.d_out**0.5,dim=1)\n",
    "        # print(x_ant_wei)\n",
    "        x_ctx_vec = x_ant_wei @ x_v\n",
    "\n",
    "        return x_ctx_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5337, -0.1051],\n",
       "        [-0.5323, -0.1080],\n",
       "        [-0.5323, -0.1079],\n",
       "        [-0.5297, -0.1076],\n",
       "        [-0.5311, -0.1066],\n",
       "        [-0.5299, -0.1081]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_in = 3\n",
    "d_out = 2\n",
    "\n",
    "sa = SimpleAttV2(d_in,d_out)\n",
    "\n",
    "x_ctx = sa.forward(inputs)\n",
    "x_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3821, 0.6605, 0.8536, 0.5932, 0.6367, 0.9826],\n",
      "        [0.2745, 0.6584, 0.2775, 0.8573, 0.8993, 0.0390],\n",
      "        [0.9268, 0.7388, 0.7179, 0.7058, 0.9156, 0.4340],\n",
      "        [0.0772, 0.3565, 0.1479, 0.5331, 0.4066, 0.2318],\n",
      "        [0.4545, 0.9737, 0.4606, 0.5159, 0.4220, 0.5786],\n",
      "        [0.9455, 0.8057, 0.6775, 0.6087, 0.6179, 0.6932]])\n",
      "tensor([[1., 1., 1., 1., 1., 1.],\n",
      "        [0., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 0., 2., 0., 2., 2.],\n",
       "        [2., 2., 0., 2., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 2.],\n",
       "        [0., 2., 2., 0., 2., 2.],\n",
       "        [2., 2., 2., 0., 0., 2.],\n",
       "        [2., 0., 2., 0., 0., 0.]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(6,6)\n",
    "print(a)\n",
    "am = torch.triu(torch.ones(6,6))\n",
    "print(am)\n",
    "torch.masked_fill(a,am.bool(),0)\n",
    "\n",
    "am.sum(dim=1,keepdim=True)\n",
    "\n",
    "drop = torch.nn.Dropout(0.5)\n",
    "drop(torch.ones(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttV3:\n",
    "    def __init__(self,d_in,d_out,bias=False) -> None:\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "\n",
    "        torch.manual_seed(123)\n",
    "        \n",
    "        self.q = torch.nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.k = torch.nn.Linear(d_in,d_out,bias=bias)\n",
    "        self.v = torch.nn.Linear(d_in,d_out,bias=bias)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_q = self.q(x)\n",
    "        x_k = self.k(x)\n",
    "        x_v = self.v(x)\n",
    "\n",
    "        x_ant_score = x_q @ x_k.T\n",
    "\n",
    "        x_ant_wei = torch.softmax(x_ant_score/self.d_out**0.5,dim=1)\n",
    "        \n",
    "        print(x_ant_wei)\n",
    "\n",
    "        # mask = torch.tril(torch.ones(x_ant_wei.shape))\n",
    "        # x_ant_wei = x_ant_wei * mask\n",
    "\n",
    "        # print(x_ant_wei)\n",
    "\n",
    "        # x_ant_wei = x_ant_wei / (x_ant_wei.sum(dim=1,keepdim=True))\n",
    "\n",
    "        # print(x_ant_wei)\n",
    "\n",
    "        mask = torch.triu(torch.ones(x_ant_wei.shape),diagonal=1)\n",
    "\n",
    "        x_ant_wei = torch.masked_fill(x_ant_wei,mask.bool(),-torch.inf)\n",
    "\n",
    "        print(x_ant_wei)\n",
    "\n",
    "        x_ant_wei = torch.softmax(x_ant_wei/x_ant_wei.shape[1]**0.5,dim=1)\n",
    "\n",
    "        print(x_ant_wei)\n",
    "\n",
    "        dorp = torch.nn.Dropout(0.5)\n",
    "        x_ant_wei = drop(x_ant_wei)\n",
    "\n",
    "        print(x_ant_wei)\n",
    "        \n",
    "        x_ctx_vec = x_ant_wei @ x_v\n",
    "\n",
    "        return x_ctx_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1717, 0.1762, 0.1761, 0.1555, 0.1627, 0.1579],\n",
      "        [0.1636, 0.1749, 0.1746, 0.1612, 0.1605, 0.1652],\n",
      "        [0.1637, 0.1749, 0.1746, 0.1611, 0.1606, 0.1651],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652, 0.1632, 0.1674],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633, 0.1639],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.1717,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1636, 0.1749,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.1637, 0.1749, 0.1746,   -inf,   -inf,   -inf],\n",
      "        [0.1636, 0.1704, 0.1702, 0.1652,   -inf,   -inf],\n",
      "        [0.1667, 0.1722, 0.1721, 0.1618, 0.1633,   -inf],\n",
      "        [0.1624, 0.1709, 0.1706, 0.1654, 0.1625, 0.1682]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4988, 0.5012, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3323, 0.3339, 0.3338, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2496, 0.2503, 0.2503, 0.2498, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2004, 0.2004, 0.1996, 0.1997, 0.0000],\n",
      "        [0.1664, 0.1670, 0.1669, 0.1666, 0.1664, 0.1668]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.9977, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6676, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4992, 0.0000, 0.5006, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3999, 0.4008, 0.0000, 0.3991, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3335]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9038,  0.4432],\n",
       "        [-0.4509,  0.2211],\n",
       "        [-0.4758, -0.1316],\n",
       "        [-0.5824,  0.0120],\n",
       "        [-0.6190, -0.0521],\n",
       "        [-0.1405, -0.0501]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_in = 3\n",
    "d_out = 2\n",
    "\n",
    "sa = SimpleAttV3(d_in,d_out)\n",
    "\n",
    "x_ctx = sa.forward(inputs)\n",
    "x_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = torch.stack((inputs,inputs),dim=0)\n",
    "inputs.shape\n",
    "batch =  torch.stack((inputs,inputs),dim=0)\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1089,  0.0141,  0.0603,  0.0695,  0.0959,  0.0246],\n",
       "         [ 0.0141,  0.0571, -0.0237,  0.0546,  0.0024,  0.0745],\n",
       "         [ 0.0603, -0.0237,  0.0514,  0.0125,  0.0588, -0.0271],\n",
       "         [ 0.0695,  0.0546,  0.0125,  0.0819,  0.0529,  0.0744],\n",
       "         [ 0.0959,  0.0024,  0.0588,  0.0529,  0.0863,  0.0086],\n",
       "         [ 0.0246,  0.0745, -0.0271,  0.0744,  0.0086,  0.0975]],\n",
       "\n",
       "        [[ 0.0103,  0.0287,  0.0344,  0.0268,  0.0202,  0.0062],\n",
       "         [ 0.0287,  0.0818,  0.0919,  0.0632,  0.0617,  0.0351],\n",
       "         [ 0.0344,  0.0919,  0.1210,  0.1091,  0.0573, -0.0108],\n",
       "         [ 0.0268,  0.0632,  0.1091,  0.1309,  0.0218, -0.0810],\n",
       "         [ 0.0202,  0.0617,  0.0573,  0.0218,  0.0547,  0.0604],\n",
       "         [ 0.0062,  0.0351, -0.0108, -0.0810,  0.0604,  0.1572]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "wei = nn.Linear(3,2,bias=False)\n",
    "ant = torch.rand(2,6,3)\n",
    "\n",
    "ant = wei(ant)\n",
    "ant.shape\n",
    "\n",
    "ant.transpose(1, 2).shape\n",
    "\n",
    "ant @ ant.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CauseAtt(nn.Module):\n",
    "    def __init__(self, context_len,in_dim,out_dim, bias=False) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.context_len = context_len\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.qw = nn.Linear(in_dim,out_dim,bias=bias)\n",
    "        self.kw = nn.Linear(in_dim,out_dim,bias=bias)\n",
    "        self.vw = nn.Linear(in_dim,out_dim,bias=bias)\n",
    "\n",
    "        self.register_buffer('mask',\n",
    "                             torch.triu(torch.ones(context_len,context_len)))\n",
    "\n",
    "    def forward(self,x):\n",
    "        b,tok,dim = x.shape\n",
    "\n",
    "        q = self.qw(x)\n",
    "        k = self.kw(x)\n",
    "        v = self.vw(x)\n",
    "\n",
    "        ant_socre = q @ k.transpose(1,2)\n",
    "        ant_socre = torch.masked_fill(ant_socre,self.mask.bool(),-torch.inf)\n",
    "\n",
    "        ant_wei = torch.softmax(ant_score/self.context_len**0.5,dim=1)        \n",
    "\n",
    "        drop = torch.nn.Dropout(0.5)\n",
    "        ant_wei = drop(ant_wei)\n",
    "\n",
    "        return ant_wei @ v\n",
    "        \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3438, -0.5346],\n",
       "         [-0.2723, -0.4053],\n",
       "         [-0.4415, -0.6877],\n",
       "         [-0.1288, -0.1892],\n",
       "         [-0.3877, -0.5945],\n",
       "         [-0.1617, -0.2719]],\n",
       "\n",
       "        [[-0.3438, -0.5346],\n",
       "         [-0.2723, -0.4053],\n",
       "         [-0.4415, -0.6877],\n",
       "         [-0.1288, -0.1892],\n",
       "         [-0.3877, -0.5945],\n",
       "         [-0.1617, -0.2719]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa = CauseAtt(6,3,2)\n",
    "\n",
    "x_ctx = sa(batch)\n",
    "x_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 4])\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [0., 0., 0., 0.]]])\n",
      "torch.Size([3, 8])\n",
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(3,4)\n",
    "b = torch.zeros(3,4)\n",
    "\n",
    "print(torch.stack([a,b],dim=1).shape)\n",
    "print(torch.stack([a,b],dim=1))\n",
    "\n",
    "\n",
    "print(torch.concat([a,b],dim=1).shape)\n",
    "print(torch.concat([a,b],dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttWrap():\n",
    "    def __init__(self,n_heads, context_len,in_dim,out_dim, bias=False):\n",
    "        self.heads = [CauseAtt(context_len,in_dim,out_dim, bias) for _ in range(n_heads)]\n",
    "\n",
    "    def forward(self,x):\n",
    "        return torch.cat([h(x) for h in self.heads],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 2])\n",
      "tensor([[[ 0.0599, -0.2556],\n",
      "         [ 0.0415, -0.0851],\n",
      "         [ 0.0787, -0.2344],\n",
      "         [-0.0018, -0.2202],\n",
      "         [ 0.0830, -0.2525],\n",
      "         [ 0.0410, -0.0354]],\n",
      "\n",
      "        [[ 0.0599, -0.2556],\n",
      "         [ 0.0415, -0.0851],\n",
      "         [ 0.0787, -0.2344],\n",
      "         [-0.0018, -0.2202],\n",
      "         [ 0.0830, -0.2525],\n",
      "         [ 0.0410, -0.0354]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa = MultiHeadAttWrap(2,6,3,1)\n",
    "\n",
    "x_ctx = sa.forward(batch)\n",
    "print(x_ctx.shape)\n",
    "print(x_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAtt(nn.Module):\n",
    "    def __init__(self,heads,cnt_len,in_dim,out_dim,blas=False,drp=0.5) -> None:\n",
    "        super().__init__()\n",
    "        assert out_dim%heads==0\n",
    "\n",
    "        self.heads = heads\n",
    "        self.head_dim = out_dim//heads\n",
    "\n",
    "        self.qw = nn.Linear(in_dim,out_dim,bias=blas)\n",
    "        self.kw = nn.Linear(in_dim,out_dim,bias=blas)\n",
    "        self.vw = nn.Linear(in_dim,out_dim,bias=blas)\n",
    "        \n",
    "        self.drop = nn.Dropout(drp)\n",
    "\n",
    "        self.register_buffer('mask',torch.triu(torch.ones(cnt_len,cnt_len),1))\n",
    "\n",
    "        self.out_prj = nn.Linear(out_dim,out_dim)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        b,cnt_len,in_dim = x.shape\n",
    "\n",
    "        q = self.qw(x)\n",
    "        k = self.kw(x)\n",
    "        v = self.vw(x)\n",
    "\n",
    "        q_v = q.view(b,cnt_len,self.heads,self.head_dim).transpose(1,2)\n",
    "        k_v = k.view(b,cnt_len,self.heads,self.head_dim).transpose(1,2)\n",
    "        v_v = v.view(b,cnt_len,self.heads,self.head_dim).transpose(1,2)\n",
    "\n",
    "        ant_score = q_v @ k_v.transpose(-2,-1)\n",
    "\n",
    "        mask = self.mask.bool()[:cnt_len,:cnt_len]\n",
    "        ant_score = torch.masked_fill(ant_score,mask,-torch.inf)\n",
    "\n",
    "        ant_score = torch.softmax(ant_score/v.shape[-1]**0.5,dim=-1)\n",
    "\n",
    "        ant_score = self.drop(ant_score)\n",
    "\n",
    "        ctx_vec = ant_score @ v_v\n",
    "        ctx_vec = ctx_vec.transpose(1,2)\n",
    "\n",
    "        ctx_vec = ctx_vec.contiguous().view(b,cnt_len,v.shape[-1])\n",
    "        \n",
    "        return self.out_prj(ctx_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 2])\n",
      "tensor([[[ 0.2675, -0.3195],\n",
      "         [ 0.6425, -0.2047],\n",
      "         [ 0.8067, -0.2182],\n",
      "         [ 0.7203, -0.2808],\n",
      "         [ 0.8400, -0.2096],\n",
      "         [ 0.7415, -0.2432]],\n",
      "\n",
      "        [[ 0.7044, -0.2822],\n",
      "         [ 0.9940, -0.1084],\n",
      "         [ 1.1206, -0.0351],\n",
      "         [ 0.7568, -0.1935],\n",
      "         [ 0.5909, -0.2919],\n",
      "         [ 0.7036, -0.2538]]], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sa = MultiHeadAtt(2,6,3,2)\n",
    "\n",
    "x_ctx = sa.forward(batch)\n",
    "print(x_ctx.shape)\n",
    "print(x_ctx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
