{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verdict.txt') as fd:\n",
    "    raw_txt = fd.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(raw_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.split(r'(\\s)',raw_txt)\n",
    "result\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = re.split(r'([,.]|\\s)',raw_txt)\n",
    "result\n",
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = [ r.strip() for r in re.split(r'([,.:;?_!()\"\\']|--|\\s)',raw_txt) if r.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preprocess))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list(set(preprocess))\n",
    "vocab_size = len(all_words)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words.extend(['<|unk|>','<|endoftext|>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {token:id for id,token in enumerate(all_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab['<|unk|>']\n",
    "vocab['<|endoftext|>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizer_v1:\n",
    "    def __init__(self,vocab) -> None:\n",
    "        self.vocab = vocab\n",
    "        self.un_vocab = [0 for i in range(0,len(vocab))]\n",
    "        for tok,id in self.vocab.items():\n",
    "            self.un_vocab[id] = tok\n",
    "\n",
    "    def encoder(self,raw_txt):\n",
    "        preprocess = [ r.strip() for r in re.split(r'([,.:;?_!()\"\\']|--|\\s)',raw_txt) if r.strip()]\n",
    "        return [ self.vocab[tok] if tok in self.vocab else self.vocab['<|unk|>']  for tok in preprocess ]\n",
    "    \n",
    "    def decoder(self,decoded):\n",
    "        return  re.sub(r'\\s+([,.:;?_!()\"\\'])',r'\\1',' '.join([self.un_vocab[id]  for id in decoded ])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SimpleTokenizer_v1(vocab=vocab)\n",
    "\n",
    "raw_txt_tst = '''I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\n",
    "'''\n",
    "decoded = st.encoder(raw_txt=raw_txt)\n",
    "print(decoded)\n",
    "raw_txt_tst_new = st.decoder(decoded=decoded)\n",
    "\n",
    "\n",
    "# raw_txt_tst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_txt_tst = \"Hello, do you like tea. Is this-- a test?\"\n",
    "st.encoder(raw_txt_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "\n",
    "\n",
    "st.encoder(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer =  tiktoken.get_encoding(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer.encode(text,allowed_special={'<|endoftext|>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verdict.txt', 'r') as f:\n",
    "    raw_text = f.read()\n",
    "raw_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded_txt = tokenizer.encode(raw_txt)\n",
    "decoded_txt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 367, 2885, 1464] [367, 2885, 1464, 1807]\n"
     ]
    }
   ],
   "source": [
    "cnt_ln = 4\n",
    "x,y = decoded_txt[:cnt_ln],decoded_txt[1:cnt_ln+1]\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40] --> 367\n",
      "[40, 367] --> 2885\n",
      "[40, 367, 2885] --> 1464\n",
      "[40, 367, 2885, 1464] --> 1807\n",
      "[40, 367, 2885, 1464, 1807] --> 3619\n",
      "[40, 367, 2885, 1464, 1807, 3619] --> 402\n",
      "[40, 367, 2885, 1464, 1807, 3619, 402] --> 271\n",
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271] --> 10899\n",
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899] --> 2138\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    print(decoded_txt[:i],'-->',decoded_txt[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LancerDataLoader(Dataset):\n",
    "    def __init__(self,txt,tok,context_length,stride) -> None:\n",
    "        self.tok = tok\n",
    "        self.input_ids = []\n",
    "        self.taget_ids = []\n",
    "\n",
    "        ids = self.tok.encode(txt,allowed_special={'<|endoftext|>'})\n",
    "\n",
    "        for i in range(0,len(ids) - context_length,stride):\n",
    "            self.input_ids.append(torch.tensor(ids[i:i+context_length]))\n",
    "            self.taget_ids.append(torch.tensor(ids[i+1:i+context_length+1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.input_ids[idx],self.taget_ids[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(text_raw,batch_size=4,context_length=256,stride=128,shuffle=True,drop_last=True):\n",
    "    tok = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    ds = LancerDataLoader(text_raw, tok,context_length,stride)\n",
    "\n",
    "    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle,drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verdict.txt', 'r') as f:\n",
    "    txt_raw = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = create_dataloader_v1(txt_raw,context_length=4,stride=1,shuffle=False,batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464],\n",
      "        [ 367, 2885, 1464, 1807]]), tensor([[ 367, 2885, 1464, 1807],\n",
      "        [2885, 1464, 1807, 3619]])]\n",
      "[tensor([[2885, 1464, 1807, 3619],\n",
      "        [1464, 1807, 3619,  402]]), tensor([[1464, 1807, 3619,  402],\n",
      "        [1807, 3619,  402,  271]])]\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(dl)\n",
    "print(next(data_iter))\n",
    "print(next(data_iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]]), tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])]\n",
      "[tensor([[  287,   262,  6001,   286],\n",
      "        [  465, 13476,    11,   339],\n",
      "        [  550,  5710,   465, 12036],\n",
      "        [   11,  6405,   257,  5527],\n",
      "        [27075,    11,   290,  4920],\n",
      "        [ 2241,   287,   257,  4489],\n",
      "        [   64,   319,   262, 34686],\n",
      "        [41976,    13,   357, 10915]]), tensor([[  262,  6001,   286,   465],\n",
      "        [13476,    11,   339,   550],\n",
      "        [ 5710,   465, 12036,    11],\n",
      "        [ 6405,   257,  5527, 27075],\n",
      "        [   11,   290,  4920,  2241],\n",
      "        [  287,   257,  4489,    64],\n",
      "        [  319,   262, 34686, 41976],\n",
      "        [   13,   357, 10915,   314]])]\n"
     ]
    }
   ],
   "source": [
    "dl = create_dataloader_v1(txt_raw,context_length=4,stride=4,shuffle=False,batch_size=8)\n",
    "data_iter = iter(dl)\n",
    "print(next(data_iter))\n",
    "print(next(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([5,4,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.3685,  0.5261, -1.0373],\n",
      "        [-0.8425,  1.5123,  0.6960],\n",
      "        [ 1.5445,  0.1742, -1.8514],\n",
      "        [ 0.4560, -0.7771,  1.2037],\n",
      "        [ 2.3678, -1.9636,  2.0754],\n",
      "        [-0.0770, -0.4712, -1.4367]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "\n",
    "embed = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embed.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0770, -0.4712, -1.4367],\n",
       "        [ 2.3678, -1.9636,  2.0754],\n",
       "        [ 1.5445,  0.1742, -1.8514],\n",
       "        [-0.8425,  1.5123,  0.6960]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed(torch.tensor([1]))\n",
    "embed(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "\n",
    "embed = torch.nn.Embedding(vocab_size, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 4\n",
    "dl = create_dataloader_v1(txt_raw,context_length=context_length,stride=4,shuffle=False,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "diter = iter(dl)\n",
    "input,target = next(diter)\n",
    "\n",
    "input_embeding = embed(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embed = torch.nn.Embedding(context_length,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 256])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_embed(torch.arange(context_length)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 256])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = input_embeding+pos_embed(torch.arange(context_length))\n",
    "t.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
